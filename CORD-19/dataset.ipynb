{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66713e27",
   "metadata": {},
   "source": [
    "Step 1: Extract data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f819964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set the root directory where the JSON file is located\n",
    "json_dir = 'document_parses/pdf_json'\n",
    "\n",
    "# Used to store processing results\n",
    "cord_uid_to_text = []\n",
    "\n",
    "# Open metadata.csv\n",
    "with open('metadata.csv', encoding='utf-8') as f_in:\n",
    "    reader = csv.DictReader(f_in)\n",
    "    for row in reader:\n",
    "        cord_uid = row.get('cord_uid', '')\n",
    "        title = row.get('title', '')\n",
    "        abstract = row.get('abstract', '')\n",
    "        authors = row.get('authors', '').split('; ')\n",
    "\n",
    "        introduction = []\n",
    "\n",
    "        # Get the JSON file path field (if it exists)\n",
    "        pdf_json_files = row.get('pdf_json_files', '')\n",
    "        if pdf_json_files:\n",
    "            for rel_path in pdf_json_files.split('; '):\n",
    "                json_path = os.path.join(json_dir, os.path.basename(rel_path))\n",
    "\n",
    "                if not os.path.exists(json_path):\n",
    "                    continue  # Skip if the file does not exist\n",
    "\n",
    "                try:\n",
    "                    with open(json_path, encoding='utf-8') as f_json:\n",
    "                        full_text_dict = json.load(f_json)\n",
    "\n",
    "                        for paragraph_dict in full_text_dict.get('body_text', []):\n",
    "                            paragraph_text = paragraph_dict.get('text', '')\n",
    "                            section_name = paragraph_dict.get('section', '')\n",
    "                            if 'intro' in section_name.lower():\n",
    "                                introduction.append(paragraph_text)\n",
    "\n",
    "                        if introduction:\n",
    "                            break \n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping error file: {json_path} Error: {e}\")\n",
    "                    continue\n",
    "\n",
    "        if introduction:\n",
    "            cord_uid_to_text.append({\n",
    "                'cord_uid': cord_uid,\n",
    "                'title': title,\n",
    "                'abstract': abstract,\n",
    "                'introduction': ' '.join(introduction)  \n",
    "            })\n",
    "\n",
    "# Writing to a CSV file\n",
    "with open('output.csv', 'w', encoding='utf-8', newline='') as f_out:\n",
    "    writer = csv.DictWriter(f_out, fieldnames=['cord_uid', 'title', 'abstract', 'introduction'])\n",
    "    writer.writeheader()\n",
    "    for row in cord_uid_to_text:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14509a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468abb9f",
   "metadata": {},
   "source": [
    "Step 2: Calculate ROUGE precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ac712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"output.csv\")  \n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\s+', ' ', str(text)).strip()\n",
    "    return text\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Calculate ROUGE precision\n",
    "rouge2_precisions = []\n",
    "rougeL_precisions = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    abstract = clean_text(row['abstract'])\n",
    "    intro = clean_text(row['introduction'])\n",
    "    scores = scorer.score(intro, abstract)  # hypothesis = abstract\n",
    "    rouge2_precisions.append(scores['rouge2'].precision)\n",
    "    rougeL_precisions.append(scores['rougeL'].precision)\n",
    "\n",
    "# Save back to CSV\n",
    "df['rouge2_precision'] = rouge2_precisions\n",
    "df['rougeL_precision'] = rougeL_precisions\n",
    "\n",
    "df.to_csv(\"output_with_rouge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output_with_rouge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88000a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c689f",
   "metadata": {},
   "source": [
    "Step 3: Filter out suspicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output_with_rouge.csv\")\n",
    "\n",
    "\n",
    "df = df[(df['rouge2_precision'] <= 0.5) & (df['rougeL_precision'] <= 0.5)]\n",
    "df = df.drop_duplicates(subset='cord_uid')\n",
    "df = df[df['introduction'].str.len() >= 2 * df['abstract'].str.len()]\n",
    "\n",
    "df = df.dropna(subset=['abstract', 'introduction'])\n",
    "df = df[(df['abstract'].str.strip() != '') & (df['introduction'].str.strip() != '')]\n",
    "\n",
    "df.to_csv(\"output_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
